{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTNlUEjtdpFe"
      },
      "source": [
        "# DDSP for Guitar: Google Colab チュートリアル\n",
        "\n",
        "DDSP for Guitar チュートリアルへようこそ！このノートブックでは、環境のセットアップ、ダミーデータセットの作成、モデルのトレーニング、そして音声の合成までの一連の流れをご案内します。\n",
        "\n",
        "## 概要\n",
        "\n",
        "このプロジェクトは、エレキギターの音声を合成するための微分可能デジタル信号処理（DDSP）の実装です。以下の機能を備えています:\n",
        "\n",
        "- ハーモニック合成（倍音生成）\n",
        "- ノイズ合成\n",
        "- ウェーブシェイパー（非線形歪み）\n",
        "- トーンスタック（3バンドEQ）\n",
        "- トランジェント分離\n",
        "\n",
        "## 必要な環境\n",
        "\n",
        "- Google Colab (GPU推奨)\n",
        "- Python 3.8以上"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BM74uQzdpFe"
      },
      "source": [
        "## 1. 環境のセットアップ\n",
        "\n",
        "まず、リポジトリをクローンして必要な依存関係をインストールします。\n",
        "\n",
        "**重要:** 次のセルで `<YOUR_REPOSITORY_URL>` を実際のリポジトリのURLに置き換えてください（例: `https://github.com/username/ddsp_guitar.git`）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JECEEBPtdpFe",
        "outputId": "161a10d6-c66c-45ac-9d73-0fefc7f3ee69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DDSP\n",
            "Obtaining file:///content/DDSP\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ddsp_guitar\n",
            "  Building editable for ddsp_guitar (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ddsp_guitar: filename=ddsp_guitar-0.1.0-0.editable-py3-none-any.whl size=2760 sha256=ac076fd8ef69ea0276b38f2ea43a5fe7af9ffd912ec68a58ed9a7a516e1edf64\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b16la1u1/wheels/e7/b9/72/3eb2b621a5220f1f69b344e78a9af854d4144e742d9bb8ded9\n",
            "Successfully built ddsp_guitar\n",
            "Installing collected packages: ddsp_guitar\n",
            "Successfully installed ddsp_guitar-0.1.0\n"
          ]
        }
      ],
      "source": [
        "%cd DDSP/\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbCieGRXdpFe"
      },
      "source": [
        "## 2. ダミーデータセットの作成\n",
        "\n",
        "トレーニングに使用するダミーデータセットを作成します。実際の使用では、エレキギターのDI（Direct Input）音源を用意してください。\n",
        "\n",
        "ここでは、サイン波をベースにした合成音声を生成してデータセットとして使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXprdoWKdpFe"
      },
      "outputs": [],
      "source": [
        "# ダミーデータセットを作成\n",
        "!python scripts/create_dummy_dataset.py \\\n",
        "    --output_dir dataset/train/audio \\\n",
        "    --num_samples 50 \\\n",
        "    --sample_rate 48000 \\\n",
        "    --duration 2.0\n",
        "\n",
        "# 検証用データも作成\n",
        "!python scripts/create_dummy_dataset.py \\\n",
        "    --output_dir dataset/val/audio \\\n",
        "    --num_samples 10 \\\n",
        "    --sample_rate 48000 \\\n",
        "    --duration 2.0\n",
        "\n",
        "print(\"\\nデータセットの作成が完了しました！\")\n",
        "print(\"トレーニングデータ: dataset/train/audio/\")\n",
        "print(\"検証データ: dataset/val/audio/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiviMrJXdpFe"
      },
      "source": [
        "## 3. モデルのトレーニング\n",
        "\n",
        "データセットが準備できたので、モデルをトレーニングします。\n",
        "\n",
        "**注意:** 完全なトレーニングには時間がかかるため、ここでは少ないエポック数で実行します。実際のプロジェクトでは、より多くのエポック（100エポック以上）を推奨します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeX16JxOdpFe",
        "outputId": "57925f80-b7b6-44d0-f945-08681cbf42d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-28 15:43:54.353364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761666234.386290    2243 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761666234.396272    2243 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761666234.420630    2243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761666234.420658    2243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761666234.420666    2243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761666234.420672    2243 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-28 15:43:54.427253: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "使用デバイス: cuda\n",
            "設定を保存: checkpoints/config.json\n",
            "\n",
            "データセットを読み込み中...\n",
            "トレーニングデータ: 1600 サンプル\n",
            "検証データ: 320 サンプル\n",
            "\n",
            "モデルを初期化中...\n",
            "総パラメータ数: 1,021,168\n",
            "学習可能パラメータ数: 1,021,168\n",
            "\n",
            "トレーニング開始: 30 エポック\n",
            "バッチサイズ: 8\n",
            "学習率: 0.0001\n",
            "============================================================\n",
            "Epoch 0:   0% 0/200 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# トレーニングを実行（デモ用に10エポック）\n",
        "!python scripts/train.py \\\n",
        "    --train_dir dataset/train/audio \\\n",
        "    --val_dir dataset/val/audio \\\n",
        "    --sample_rate 48000 \\\n",
        "    --segment_seconds 1.0 \\\n",
        "    --batch_size 8 \\\n",
        "    --epochs 30 \\\n",
        "    --lr 1e-4 \\\n",
        "    --num_harm 64 \\\n",
        "    --num_noise 8 \\\n",
        "    --checkpoint_dir checkpoints \\\n",
        "    --log_dir logs \\\n",
        "    --save_every 5 \\\n",
        "    --device cuda\n",
        "\n",
        "print(\"\\nトレーニングが完了しました！\")\n",
        "print(\"チェックポイント: checkpoints/\")\n",
        "print(\"TensorBoardログ: logs/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0ku4JvydpFe"
      },
      "source": [
        "## 4. トレーニング結果の確認\n",
        "\n",
        "TensorBoardを使用してトレーニングの進捗を確認します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwLpYGWBdpFe"
      },
      "outputs": [],
      "source": [
        "# TensorBoardを起動\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n",
        "\n",
        "# 最新のログディレクトリを表示\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "log_dir = Path('logs')\n",
        "if log_dir.exists():\n",
        "    log_dirs = sorted(log_dir.glob('*'))\n",
        "    if log_dirs:\n",
        "        print(f\"最新のログ: {log_dirs[-1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7unyPAedpFe"
      },
      "source": [
        "## 5. モデルの推論\n",
        "\n",
        "トレーニングしたモデルを使って音声を合成してみましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfrioJGmdpFe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from ddsp_guitar.model import GuitarDDSP\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from IPython.display import Audio\n",
        "from pathlib import Path\n",
        "\n",
        "# 設定\n",
        "SAMPLE_RATE = 48000\n",
        "AUDIO_LENGTH_SECONDS = 2\n",
        "FRAME_RATE = 250\n",
        "HOP_SIZE = SAMPLE_RATE // FRAME_RATE\n",
        "\n",
        "# デバイスの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"使用デバイス: {device}\")\n",
        "\n",
        "# モデルの読み込み\n",
        "model = GuitarDDSP(sample_rate=SAMPLE_RATE, num_harm=64, num_noise=8, device=device)\n",
        "\n",
        "# チェックポイントから重みを読み込み（ベストモデルまたは最終モデル）\n",
        "checkpoint_path = Path('checkpoints/best_model.pt')\n",
        "if not checkpoint_path.exists():\n",
        "    checkpoint_path = Path('checkpoints/final_model.pt')\n",
        "\n",
        "if checkpoint_path.exists():\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"チェックポイントを読み込みました: {checkpoint_path}\")\n",
        "else:\n",
        "    print(\"チェックポイントが見つかりません。初期化されたモデルを使用します。\")\n",
        "\n",
        "model.eval()\n",
        "print(f\"モデルパラメータ数: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru9i7j8EdpFe"
      },
      "source": [
        "### 5.1 テスト音声の合成\n",
        "\n",
        "ダミーの入力パラメータを使って音声を合成します。実際の使用では、入力音声から特徴量（基本周波数、ラウドネスなど）を抽出します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViMb1yqkdpFe"
      },
      "outputs": [],
      "source": [
        "# 入力パラメータの作成\n",
        "batch_size = 1\n",
        "audio_length_samples = AUDIO_LENGTH_SECONDS * SAMPLE_RATE\n",
        "n_frames = audio_length_samples // HOP_SIZE\n",
        "\n",
        "# 条件付け入力（通常は入力音声から抽出される特徴量）\n",
        "conditioning_input = torch.randn(batch_size, n_frames).to(device)\n",
        "\n",
        "# 基本周波数（f0）- A2音（110Hz）からE3音（165Hz）へのスライド\n",
        "f0_start = 110.0  # A2\n",
        "f0_end = 165.0    # E3\n",
        "f0_values = torch.linspace(f0_start, f0_end, n_frames).unsqueeze(0).to(device)\n",
        "\n",
        "# ラウドネス - 時間とともに減衰\n",
        "loudness_values = torch.linspace(-20.0, -40.0, n_frames).unsqueeze(0).to(device)\n",
        "\n",
        "print(f\"入力形状:\")\n",
        "print(f\"  conditioning_input: {conditioning_input.shape}\")\n",
        "print(f\"  f0: {f0_values.shape}\")\n",
        "print(f\"  loudness: {loudness_values.shape}\")\n",
        "\n",
        "# 音声を合成\n",
        "print(\"\\n音声を合成中...\")\n",
        "with torch.no_grad():\n",
        "    output_audio = model(conditioning_input, f0_values, loudness_values)\n",
        "\n",
        "print(\"合成完了！\")\n",
        "print(f\"出力音声形状: {output_audio.shape}\")\n",
        "\n",
        "# CPUに移動して保存\n",
        "output_audio_np = output_audio.cpu().numpy().squeeze()\n",
        "\n",
        "# 正規化\n",
        "output_audio_np = output_audio_np / (np.abs(output_audio_np).max() + 1e-8) * 0.9\n",
        "\n",
        "# 保存\n",
        "output_filename = 'synthesized_guitar.wav'\n",
        "sf.write(output_filename, output_audio_np, SAMPLE_RATE)\n",
        "print(f\"音声を保存しました: {output_filename}\")\n",
        "\n",
        "# 再生\n",
        "Audio(output_audio_np, rate=SAMPLE_RATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpSKsvgydpFe"
      },
      "source": [
        "### 5.2 メロディの合成\n",
        "\n",
        "複数の音符を使ってシンプルなメロディを合成してみましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djX5EAKXdpFe"
      },
      "outputs": [],
      "source": [
        "# メロディの定義（音符と長さ）\n",
        "# C4, D4, E4, F4, G4, A4, B4, C5（ドレミファソラシド）\n",
        "melody_notes = [\n",
        "    (261.63, 0.3),  # C4\n",
        "    (293.66, 0.3),  # D4\n",
        "    (329.63, 0.3),  # E4\n",
        "    (349.23, 0.3),  # F4\n",
        "    (392.00, 0.3),  # G4\n",
        "    (440.00, 0.3),  # A4\n",
        "    (493.88, 0.3),  # B4\n",
        "    (523.25, 0.5),  # C5（最後の音は長く）\n",
        "]\n",
        "\n",
        "# メロディ全体の長さを計算\n",
        "total_duration = sum(duration for _, duration in melody_notes)\n",
        "total_samples = int(total_duration * SAMPLE_RATE)\n",
        "total_frames = total_samples // HOP_SIZE\n",
        "\n",
        "# f0とラウドネスのシーケンスを作成\n",
        "f0_sequence = []\n",
        "loudness_sequence = []\n",
        "\n",
        "current_frame = 0\n",
        "for freq, duration in melody_notes:\n",
        "    num_frames = int((duration * SAMPLE_RATE) // HOP_SIZE)\n",
        "\n",
        "    # 各音符のf0（一定）\n",
        "    f0_sequence.extend([freq] * num_frames)\n",
        "\n",
        "    # ラウドネス（アタック→サスティン→リリース）\n",
        "    attack_frames = num_frames // 4\n",
        "    sustain_frames = num_frames // 2\n",
        "    release_frames = num_frames - attack_frames - sustain_frames\n",
        "\n",
        "    attack = np.linspace(-35, -15, attack_frames)\n",
        "    sustain = np.full(sustain_frames, -15)\n",
        "    release = np.linspace(-15, -45, release_frames)\n",
        "\n",
        "    loudness_sequence.extend(attack.tolist())\n",
        "    loudness_sequence.extend(sustain.tolist())\n",
        "    loudness_sequence.extend(release.tolist())\n",
        "\n",
        "# テンソルに変換\n",
        "f0_tensor = torch.tensor(f0_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "loudness_tensor = torch.tensor(loudness_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "conditioning_tensor = torch.randn(1, len(f0_sequence)).to(device)\n",
        "\n",
        "print(f\"メロディの長さ: {total_duration:.2f}秒\")\n",
        "print(f\"フレーム数: {len(f0_sequence)}\")\n",
        "\n",
        "# メロディを合成\n",
        "print(\"\\nメロディを合成中...\")\n",
        "with torch.no_grad():\n",
        "    melody_audio = model(conditioning_tensor, f0_tensor, loudness_tensor)\n",
        "\n",
        "melody_audio_np = melody_audio.cpu().numpy().squeeze()\n",
        "melody_audio_np = melody_audio_np / (np.abs(melody_audio_np).max() + 1e-8) * 0.9\n",
        "\n",
        "# 保存\n",
        "melody_filename = 'synthesized_melody.wav'\n",
        "sf.write(melody_filename, melody_audio_np, SAMPLE_RATE)\n",
        "print(f\"メロディを保存しました: {melody_filename}\")\n",
        "\n",
        "# 再生\n",
        "Audio(melody_audio_np, rate=SAMPLE_RATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfKMB34OdpFe"
      },
      "source": [
        "## 6. 次のステップ\n",
        "\n",
        "このチュートリアルでは基本的な使い方を紹介しましたが、より高度な使い方には以下があります：\n",
        "\n",
        "### 6.1 実際のギター音源を使う\n",
        "\n",
        "ダミーデータの代わりに、実際のエレキギターのDI（Direct Input）音源を使用してトレーニングすることで、より高品質な結果が得られます。\n",
        "\n",
        "```python\n",
        "# 実際のデータセットの準備\n",
        "# 1. wavファイルをdataset/train/audio/に配置\n",
        "# 2. 同様にdataset/val/audio/に検証データを配置\n",
        "# 3. トレーニングスクリプトを実行\n",
        "```\n",
        "\n",
        "### 6.2 ハイパーパラメータの調整\n",
        "\n",
        "以下のパラメータを調整することで、モデルの性能を向上させることができます：\n",
        "\n",
        "- `num_harm`: ハーモニクス数（デフォルト: 64）\n",
        "- `num_noise`: ノイズバンド数（デフォルト: 8）\n",
        "- `lr`: 学習率（デフォルト: 1e-4）\n",
        "- `batch_size`: バッチサイズ（GPUメモリに応じて調整）\n",
        "- `epochs`: エポック数（100エポック以上推奨）\n",
        "\n",
        "### 6.3 リアルタイム処理\n",
        "\n",
        "`ddsp_guitar/rt/engine.py`を使用することで、リアルタイムでの音声処理が可能です。\n",
        "\n",
        "### 6.4 モデルの保存とエクスポート\n",
        "\n",
        "```python\n",
        "# モデルの保存\n",
        "torch.save(model.state_dict(), 'guitar_ddsp_model.pth')\n",
        "\n",
        "# モデルの読み込み\n",
        "model.load_state_dict(torch.load('guitar_ddsp_model.pth'))\n",
        "```\n",
        "\n",
        "## 参考資料\n",
        "\n",
        "- [DDSP論文](https://arxiv.org/abs/2001.04643)\n",
        "- [プロジェクトリポジトリ](https://github.com/your-repo/ddsp_guitar)\n",
        "- [ドキュメント](docs/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjQLkQDSdpFe"
      },
      "source": [
        "## 7. トラブルシューティング\n",
        "\n",
        "### GPU メモリ不足の場合\n",
        "\n",
        "バッチサイズを減らすか、セグメント長を短くしてください：\n",
        "\n",
        "```bash\n",
        "!python scripts/train.py --batch_size 2 --segment_seconds 0.5\n",
        "```\n",
        "\n",
        "### トレーニングが不安定な場合\n",
        "\n",
        "学習率を下げるか、勾配クリッピングを調整してください：\n",
        "\n",
        "```bash\n",
        "!python scripts/train.py --lr 5e-5 --grad_clip 0.5\n",
        "```\n",
        "\n",
        "### 音質が悪い場合\n",
        "\n",
        "- より多くのデータでトレーニングする\n",
        "- エポック数を増やす（100エポック以上）\n",
        "- ハーモニクス数を増やす（`--num_harm 128`）\n",
        "- 実際のギター音源を使用する\n",
        "\n",
        "## おわりに\n",
        "\n",
        "このチュートリアルを通じて、DDSP for Guitarの基本的な使い方を学びました。\n",
        "質問や問題がある場合は、GitHubのIssueで報告してください。\n",
        "\n",
        "Happy coding!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}